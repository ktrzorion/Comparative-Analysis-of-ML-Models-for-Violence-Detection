{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gm4pukkIOO6R"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Ra9Ck7DOXo1"
      },
      "outputs": [],
      "source": [
        "# Unzip the dataset\n",
        "with zipfile.ZipFile('Violence Detection.v1-v1.multiclass.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('multiclass_dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gweHevHvV_jN"
      },
      "outputs": [],
      "source": [
        "# Load your CSV dataset\n",
        "train_csv_path = 'multiclass_dataset/train/_classes.csv'\n",
        "valid_csv_path = 'multiclass_dataset/valid/_classes.csv'\n",
        "test_csv_path = 'multiclass_dataset/test/_classes.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8EjE8SOWBJZ"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv(train_csv_path)\n",
        "valid_data = pd.read_csv(valid_csv_path)\n",
        "test_data = pd.read_csv(test_csv_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSz_PtaWWCX8"
      },
      "outputs": [],
      "source": [
        "# Preprocess the image data\n",
        "image_data = []\n",
        "image_labels = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aK2QXveeWoIo"
      },
      "outputs": [],
      "source": [
        "image_directory = 'multiclass_dataset/train/'  # Adjust to the appropriate folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uj1cLzTBcTHb",
        "outputId": "34e7e67f-cbe1-4990-eede-767d7d303930"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['filename', ' NonViolence', ' Violence'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(train_data.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZ80-oAPWot3"
      },
      "outputs": [],
      "source": [
        "for index, row in train_data.iterrows():\n",
        "    filename = row['filename']\n",
        "    label_nonViolence = row[' NonViolence']  # Note the leading space\n",
        "    label_Violence = row[' Violence']  # Note the leading space\n",
        "\n",
        "    image_path = os.path.join(image_directory, filename)\n",
        "    image = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
        "    image = tf.keras.preprocessing.image.img_to_array(image)\n",
        "    image = preprocess_input(image)\n",
        "\n",
        "    image_data.append(image)\n",
        "    image_labels.append([label_nonViolence, label_Violence])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMkC3iXiWqx_"
      },
      "outputs": [],
      "source": [
        "image_data = np.array(image_data)\n",
        "image_labels = np.array(image_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnnQ0ZIlWshj"
      },
      "outputs": [],
      "source": [
        "# Load the ResNet-50 model pre-trained on ImageNet\n",
        "image_input = Input(shape=(224, 224, 3))\n",
        "resnet_base = ResNet50(weights='imagenet', include_top=False, input_tensor=image_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYHpJm4VWvVb"
      },
      "outputs": [],
      "source": [
        "# Combine image data and text data (sequences) if needed\n",
        "\n",
        "# Build a classification head\n",
        "x = Flatten()(resnet_base.output)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "num_classes = 2  # Two classes: nonViolence and Violence\n",
        "output = Dense(num_classes, activation='softmax')(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJWrhKs1WxJg"
      },
      "outputs": [],
      "source": [
        "# Create the hybrid model\n",
        "model = Model(inputs=image_input, outputs=output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKkyYYB1Wy8D"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEXmXkG1W0tt"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into training, validation, and test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(image_data, image_labels, test_size=0.2, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMEDEsrSW2Ug",
        "outputId": "ec36816c-bc0a-4869-d827-5309ff49adfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "30/30 [==============================] - 56s 629ms/step - loss: 13.1776 - accuracy: 0.5356 - val_loss: 150867.6250 - val_accuracy: 0.5342\n",
            "Epoch 2/10\n",
            "30/30 [==============================] - 18s 596ms/step - loss: 13.4073 - accuracy: 0.5409 - val_loss: 983730.3750 - val_accuracy: 0.4658\n",
            "Epoch 3/10\n",
            "30/30 [==============================] - 19s 623ms/step - loss: 7.2328 - accuracy: 0.5645 - val_loss: 15865.8574 - val_accuracy: 0.5427\n",
            "Epoch 4/10\n",
            "30/30 [==============================] - 18s 613ms/step - loss: 23.7117 - accuracy: 0.5570 - val_loss: 11840.0947 - val_accuracy: 0.4615\n",
            "Epoch 5/10\n",
            "30/30 [==============================] - 19s 639ms/step - loss: 63.2047 - accuracy: 0.5581 - val_loss: 1050667.8750 - val_accuracy: 0.5342\n",
            "Epoch 6/10\n",
            "30/30 [==============================] - 19s 625ms/step - loss: 93.0837 - accuracy: 0.5490 - val_loss: 1073367.8750 - val_accuracy: 0.5342\n",
            "Epoch 7/10\n",
            "30/30 [==============================] - 19s 617ms/step - loss: 109.8684 - accuracy: 0.5655 - val_loss: 18508.8418 - val_accuracy: 0.4786\n",
            "Epoch 8/10\n",
            "30/30 [==============================] - 19s 634ms/step - loss: 102.1091 - accuracy: 0.5682 - val_loss: 4913.5737 - val_accuracy: 0.5256\n",
            "Epoch 9/10\n",
            "30/30 [==============================] - 18s 617ms/step - loss: 302.2389 - accuracy: 0.5730 - val_loss: 28950.9609 - val_accuracy: 0.5171\n",
            "Epoch 10/10\n",
            "30/30 [==============================] - 19s 639ms/step - loss: 135.2911 - accuracy: 0.5864 - val_loss: 4333.6123 - val_accuracy: 0.5171\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7db6f1e46e60>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# Train the model\n",
        "batch_size = 64\n",
        "epochs = 10\n",
        "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3p51pq3uW4K5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1552801d-57ef-4f0b-fe29-802279e9c2e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 1s 92ms/step - loss: 4655.0845 - accuracy: 0.5000\n",
            "Test Accuracy: 50.00%\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}